---
language:
- zh
- en
tags:
- glm
- chatglm
- thudm
---
# ChatGLM3-6B-32K
<p align="center">
  ğŸ’» <a href="https://github.com/THUDM/ChatGLM" target="_blank">Github Repo</a> â€¢ ğŸ¦ <a href="https://twitter.com/thukeg" target="_blank">Twitter</a> â€¢ ğŸ“ƒ <a href="https://arxiv.org/abs/2103.10360" target="_blank">[GLM@ACL 22]</a> <a href="https://github.com/THUDM/GLM" target="_blank">[GitHub]</a> â€¢ ğŸ“ƒ <a href="https://arxiv.org/abs/2210.02414" target="_blank">[GLM-130B@ICLR 23]</a> <a href="https://github.com/THUDM/GLM-130B" target="_blank">[GitHub]</a> <br>
</p>

<p align="center">
    ğŸ‘‹ Join our <a href="https://join.slack.com/t/chatglm/shared_invite/zt-25ti5uohv-A_hs~am_D3Q8XPZMpj7wwQ" target="_blank">Slack</a> and <a href="https://github.com/THUDM/ChatGLM/blob/main/resources/WECHAT.md" target="_blank">WeChat</a>
</p>
<p align="center">
ğŸ“Experience the larger-scale ChatGLM model at <a href="https://www.chatglm.cn">chatglm.cn</a>
</p>

## ä»‹ç»
ChatGLM3-6B-32Kåœ¨[ChatGLM3-6B](https://huggingface.co/THUDM/chatglm3-6b)çš„åŸºç¡€ä¸Šè¿›ä¸€æ­¥å¼ºåŒ–äº†å¯¹äºé•¿æ–‡æœ¬çš„ç†è§£èƒ½åŠ›ï¼Œèƒ½å¤Ÿæ›´å¥½çš„å¤„ç†æœ€å¤š32Ké•¿åº¦çš„ä¸Šä¸‹æ–‡ã€‚å…·ä½“åœ°ï¼Œæˆ‘ä»¬å¯¹ä½ç½®ç¼–ç è¿›è¡Œäº†æ›´æ–°ï¼Œå¹¶è®¾è®¡äº†æ›´æœ‰é’ˆå¯¹æ€§çš„é•¿æ–‡æœ¬è®­ç»ƒæ–¹æ³•ï¼Œåœ¨å¯¹è¯é˜¶æ®µä½¿ç”¨ 32K çš„ä¸Šä¸‹æ–‡é•¿åº¦è®­ç»ƒã€‚åœ¨å®é™…çš„ä½¿ç”¨ä¸­ï¼Œå¦‚æœæ‚¨é¢ä¸´çš„ä¸Šä¸‹æ–‡é•¿åº¦åŸºæœ¬åœ¨ **8K ä»¥å†…**ï¼Œæˆ‘ä»¬æ¨èä½¿ç”¨[ChatGLM3-6B](https://huggingface.co/THUDM/chatglm3-6b)ï¼›å¦‚æœæ‚¨éœ€è¦å¤„ç†**è¶…è¿‡ 8K** çš„ä¸Šä¸‹æ–‡é•¿åº¦ï¼Œæˆ‘ä»¬æ¨èä½¿ç”¨ChatGLM3-6B-32Kã€‚


ChatGLM3-6B æ˜¯ ChatGLM ç³»åˆ—æœ€æ–°ä¸€ä»£çš„å¼€æºæ¨¡å‹ï¼Œåœ¨ä¿ç•™äº†å‰ä¸¤ä»£æ¨¡å‹å¯¹è¯æµç•…ã€éƒ¨ç½²é—¨æ§›ä½ç­‰ä¼—å¤šä¼˜ç§€ç‰¹æ€§çš„åŸºç¡€ä¸Šï¼ŒChatGLM3-6B å¼•å…¥äº†å¦‚ä¸‹ç‰¹æ€§ï¼š

1. **æ›´å¼ºå¤§çš„åŸºç¡€æ¨¡å‹ï¼š** ChatGLM3-6B çš„åŸºç¡€æ¨¡å‹ ChatGLM3-6B-Base é‡‡ç”¨äº†æ›´å¤šæ ·çš„è®­ç»ƒæ•°æ®ã€æ›´å……åˆ†çš„è®­ç»ƒæ­¥æ•°å’Œæ›´åˆç†çš„è®­ç»ƒç­–ç•¥ã€‚åœ¨è¯­ä¹‰ã€æ•°å­¦ã€æ¨ç†ã€ä»£ç ã€çŸ¥è¯†ç­‰ä¸åŒè§’åº¦çš„æ•°æ®é›†ä¸Šæµ‹è¯„æ˜¾ç¤ºï¼ŒChatGLM3-6B-Base å…·æœ‰åœ¨ 10B ä»¥ä¸‹çš„é¢„è®­ç»ƒæ¨¡å‹ä¸­æœ€å¼ºçš„æ€§èƒ½ã€‚
2. **æ›´å®Œæ•´çš„åŠŸèƒ½æ”¯æŒï¼š** ChatGLM3-6B é‡‡ç”¨äº†å…¨æ–°è®¾è®¡çš„ [Prompt æ ¼å¼](PROMPT.md)ï¼Œé™¤æ­£å¸¸çš„å¤šè½®å¯¹è¯å¤–ã€‚åŒæ—¶åŸç”Ÿæ”¯æŒ[å·¥å…·è°ƒç”¨](tool_using/README.md)ï¼ˆFunction Callï¼‰ã€ä»£ç æ‰§è¡Œï¼ˆCode Interpreterï¼‰å’Œ Agent ä»»åŠ¡ç­‰å¤æ‚åœºæ™¯ã€‚
3. **æ›´å…¨é¢çš„å¼€æºåºåˆ—ï¼š** é™¤äº†å¯¹è¯æ¨¡å‹ ChatGLM3-6B å¤–ï¼Œè¿˜å¼€æºäº†åŸºç¡€æ¨¡å‹ ChatGLM-6B-Baseã€é•¿æ–‡æœ¬å¯¹è¯æ¨¡å‹ ChatGLM3-6B-32Kã€‚ä»¥ä¸Šæ‰€æœ‰æƒé‡å¯¹å­¦æœ¯ç ”ç©¶**å®Œå…¨å¼€æ”¾**ï¼Œåœ¨å¡«å†™[é—®å·](https://open.bigmodel.cn/mla/form)è¿›è¡Œç™»è®°å**äº¦å…è®¸å…è´¹å•†ä¸šä½¿ç”¨**ã€‚


## è½¯ä»¶ä¾èµ–

```shell
pip install protobuf transformers==4.30.2 cpm_kernels torch>=2.0 gradio mdtex2html sentencepiece accelerate
```

## æ¨¡å‹ä¸‹è½½

modelscope APIä¸‹è½½
```shell
pip install modelscope
```

```python
from modelscope import snapshot_download
model_dir = snapshot_download("ZhipuAI/chatglm3-6b-32k", revision = "master")
```

gitä¸‹è½½
```shell
git lfs install
git clone https://www.modelscope.cn/ZhipuAI/chatglm3-6b-32k.git
```




## ä»£ç è°ƒç”¨ 

å¯ä»¥é€šè¿‡å¦‚ä¸‹ä»£ç è°ƒç”¨ ChatGLM3-6B æ¨¡å‹æ¥ç”Ÿæˆå¯¹è¯ï¼š

```python
from modelscope import AutoTokenizer, AutoModel, snapshot_download
model_dir = snapshot_download("ZhipuAI/chatglm3-6b-32k", revision = "master")
tokenizer = AutoTokenizer.from_pretrained(model_dir, trust_remote_code=True)
model = AutoModel.from_pretrained(model_dir, trust_remote_code=True).half().cuda()
model = model.eval()
response, history = model.chat(tokenizer, "ä½ å¥½", history=[])
print(response)
response, history = model.chat(tokenizer, "æ™šä¸Šç¡ä¸ç€åº”è¯¥æ€ä¹ˆåŠ", history=history)
print(response)
```

å…³äºæ›´å¤šçš„ä½¿ç”¨è¯´æ˜ï¼ŒåŒ…æ‹¬å¦‚ä½•è¿è¡Œå‘½ä»¤è¡Œå’Œç½‘é¡µç‰ˆæœ¬çš„ DEMOï¼Œä»¥åŠä½¿ç”¨æ¨¡å‹é‡åŒ–ä»¥èŠ‚çœæ˜¾å­˜ï¼Œè¯·å‚è€ƒæˆ‘ä»¬çš„ [Github Repo](https://github.com/THUDM/ChatGLM)ã€‚

For more instructions, including how to run CLI and web demos, and model quantization, please refer to our [Github Repo](https://github.com/THUDM/ChatGLM).


## åè®®

æœ¬ä»“åº“çš„ä»£ç ä¾ç…§ [Apache-2.0](LICENSE) åè®®å¼€æºï¼ŒChatGLM3-6B æ¨¡å‹çš„æƒé‡çš„ä½¿ç”¨åˆ™éœ€è¦éµå¾ª [Model License](MODEL_LICENSE)ã€‚

## å¼•ç”¨

å¦‚æœä½ è§‰å¾—æˆ‘ä»¬çš„å·¥ä½œæœ‰å¸®åŠ©çš„è¯ï¼Œè¯·è€ƒè™‘å¼•ç”¨ä¸‹åˆ—è®ºæ–‡ã€‚

```
@article{zeng2022glm,
  title={Glm-130b: An open bilingual pre-trained model},
  author={Zeng, Aohan and Liu, Xiao and Du, Zhengxiao and Wang, Zihan and Lai, Hanyu and Ding, Ming and Yang, Zhuoyi and Xu, Yifan and Zheng, Wendi and Xia, Xiao and others},
  journal={arXiv preprint arXiv:2210.02414},
  year={2022}
}
```
```
@inproceedings{du2022glm,
  title={GLM: General Language Model Pretraining with Autoregressive Blank Infilling},
  author={Du, Zhengxiao and Qian, Yujie and Liu, Xiao and Ding, Ming and Qiu, Jiezhong and Yang, Zhilin and Tang, Jie},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={320--335},
  year={2022}
}
```
